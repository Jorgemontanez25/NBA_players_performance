{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd8eedc",
   "metadata": {},
   "source": [
    "# Modeling: Predicting High-Scoring Games(20+ Points)\n",
    "\n",
    "## Objective\n",
    "\n",
    "This notebook demostrates a reproducible machine learning workflow using an analysis-ready dataset derived \n",
    "from NBA play-to-play data.\n",
    "\n",
    "We build baseline predective models to classify whether a player will score **20+ points** in a game.\n",
    "The emphasis is on a correct ML workflow (feature preparation, splitting, baselines, evaluation), not on\n",
    "maximizing accuracy.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "Input data is the processed feature table exported from the EDA pipeline:\n",
    "\n",
    "    -'data/processed/player_game_feature.csv'\n",
    "    \n",
    "Each row represents a **player-game** observation with engineered metrics such as:\n",
    "\n",
    "    -'final_points'(scoring outcome)\n",
    "    -'rebound_events'(from play-by-play)\n",
    "    -season context('season_id','season_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6deb163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import  classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa786fa0",
   "metadata": {},
   "source": [
    "## Load Processed Data \n",
    "\n",
    "We load rhe feature table produced during the EDA phase. This notebook does not depend on the raw AQLite file, making it lightweight and reproducible for GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f237949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>player1_id</th>\n",
       "      <th>final_points</th>\n",
       "      <th>full_name</th>\n",
       "      <th>rebound_events</th>\n",
       "      <th>season_id</th>\n",
       "      <th>season_type</th>\n",
       "      <th>game_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11300001</td>\n",
       "      <td>200757</td>\n",
       "      <td>8</td>\n",
       "      <td>Thabo Sefolosha</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12013</td>\n",
       "      <td>Pre Season</td>\n",
       "      <td>2013-10-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11300001</td>\n",
       "      <td>201142</td>\n",
       "      <td>24</td>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12013</td>\n",
       "      <td>Pre Season</td>\n",
       "      <td>2013-10-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11300001</td>\n",
       "      <td>201586</td>\n",
       "      <td>15</td>\n",
       "      <td>Serge Ibaka</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12013</td>\n",
       "      <td>Pre Season</td>\n",
       "      <td>2013-10-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11300001</td>\n",
       "      <td>201934</td>\n",
       "      <td>4</td>\n",
       "      <td>Hasheem Thabeet</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12013</td>\n",
       "      <td>Pre Season</td>\n",
       "      <td>2013-10-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11300001</td>\n",
       "      <td>202704</td>\n",
       "      <td>9</td>\n",
       "      <td>Reggie Jackson</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12013</td>\n",
       "      <td>Pre Season</td>\n",
       "      <td>2013-10-05 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    game_id  player1_id  final_points        full_name  rebound_events  \\\n",
       "0  11300001      200757             8  Thabo Sefolosha             2.0   \n",
       "1  11300001      201142            24     Kevin Durant             8.0   \n",
       "2  11300001      201586            15      Serge Ibaka             6.0   \n",
       "3  11300001      201934             4  Hasheem Thabeet             5.0   \n",
       "4  11300001      202704             9   Reggie Jackson             2.0   \n",
       "\n",
       "   season_id season_type            game_date  \n",
       "0      12013  Pre Season  2013-10-05 00:00:00  \n",
       "1      12013  Pre Season  2013-10-05 00:00:00  \n",
       "2      12013  Pre Season  2013-10-05 00:00:00  \n",
       "3      12013  Pre Season  2013-10-05 00:00:00  \n",
       "4      12013  Pre Season  2013-10-05 00:00:00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"../data/processed/player_game_features.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f00cb2",
   "metadata": {},
   "source": [
    "## Quick Validation\n",
    "\n",
    "We verify required columns exist and check basic mossongness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb171d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_name         0.001403\n",
       "game_id           0.000000\n",
       "player1_id        0.000000\n",
       "final_points      0.000000\n",
       "rebound_events    0.000000\n",
       "season_id         0.000000\n",
       "season_type       0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "required_cols=[\"game_id\",\"player1_id\", \"full_name\", \"final_points\", \"rebound_events\", \"season_id\", \"season_type\"]\n",
    "missing=[c for c in required_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "df[required_cols].isna().mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e20289",
   "metadata": {},
   "source": [
    "####  Validation Result\n",
    "\n",
    "The dataset shows:\n",
    "\n",
    "- No missing values for core modeling features\n",
    "- Correct joins for season and game metadata\n",
    "- Only negligible missing values for player names (<0.2%)\n",
    "\n",
    "This confirms that feature engineering and merges were successful.  \n",
    "We proceed to modeling with confidence in data integrity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ff3143",
   "metadata": {},
   "source": [
    "## Define Target: 20+ Points\n",
    "\n",
    "We define a binary classification target:\n",
    "\n",
    "- '1' if the player scored **20 or more points**\n",
    "- '0' otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3bb3fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final_points</th>\n",
       "      <th>rebound_events</th>\n",
       "      <th>target_20plus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   final_points  rebound_events  target_20plus\n",
       "0             8             2.0              0\n",
       "1            24             8.0              1\n",
       "2            15             6.0              0\n",
       "3             4             5.0              0\n",
       "4             9             2.0              0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"target_20plus\"]=(df[\"final_points\"] >= 20).astype(int)\n",
    "\n",
    "#keep rows with essential context\n",
    "df= df.dropna(subset=[\"season_id\",\"season_type\"])\n",
    "\n",
    "#Ensure correct dtypes\n",
    "df[\"player1_id\"]=df[\"player1_id\"].astype(str)\n",
    "df[\"season_id\"]=df[\"season_id\"].astype(str)\n",
    "df[\"season_type\"]=df[\"season_type\"].astype(str)\n",
    "\n",
    "df[[\"final_points\", \"rebound_events\", \"target_20plus\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15811c76",
   "metadata": {},
   "source": [
    "## Feature Set & Train/Test Split\n",
    "\n",
    "### Features (simple + realistic)\n",
    "\n",
    "- 'rebound_events'(numeric)\n",
    "- 'season_id' (categorical)\n",
    "- 'season_type' (categorical)\n",
    "\n",
    ">Note: We intentionally **exclude 'player1_id'** to avoid the model simply learning player identity.\n",
    "This improves generalization and better reflects real predictive modeling.\n",
    "\n",
    "We split with stratification to perserve class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7e89146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((436301, 3), (109076, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_num=[\"rebound_events\"]\n",
    "features_cat=[\"season_id\",\"season_type\"]\n",
    "\n",
    "X=df[features_num + features_cat]\n",
    "y= df[\"target_20plus\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a29e54",
   "metadata": {},
   "source": [
    "## Baseline Model: Logistic Regression\n",
    "\n",
    "Logistic Regression is a strong, interpretable baseline for binary classification. \n",
    "We use one-hot encoding for categorical variables via a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "045679eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92     93110\n",
      "           1       0.46      0.03      0.06     15966\n",
      "\n",
      "    accuracy                           0.85    109076\n",
      "   macro avg       0.66      0.51      0.49    109076\n",
      "weighted avg       0.80      0.85      0.79    109076\n",
      "\n",
      "ROC AUC : 0.6961319714768709\n"
     ]
    }
   ],
   "source": [
    "preprocess = ColumnTransformer(\n",
    "    transformers= [\n",
    "        (\"num\",\"passthrough\", features_num),\n",
    "        (\"cat\", OneHotEncoder (handle_unknown=\"ignore\"), features_cat),\n",
    "    ]\n",
    ")\n",
    "\n",
    "log_reg=Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"model\", LogisticRegression(max_iter=300))\n",
    "    ]\n",
    ")\n",
    "\n",
    "log_reg.fit(X_train,y_train)\n",
    "\n",
    "y_pred= log_reg.predict(X_test)\n",
    "y_prob= log_reg.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(classification_report (y_test, y_pred))\n",
    "print(\"ROC AUC :\", roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc9ea3d",
   "metadata": {},
   "source": [
    "#### Model Evaluation\n",
    "\n",
    "We trained a Logistic Regression classifier to predict whether a player scores **20+ points** in a game using basic contextual and performance features.\n",
    "\n",
    "##### Key observations\n",
    "\n",
    "- Dataset is highly imbalanced (~85% non-20pt games)\n",
    "- High overall accuracy (0.85) is misleading due to class imbalance\n",
    "- Strong performance for the majority class (non-scoring games)\n",
    "- Weak recall for 20+ point games (model misses most high-scoring performances)\n",
    "- ROC AUC ≈ 0.70 indicates moderate predictive signal\n",
    "\n",
    "##### Interpretation\n",
    "\n",
    "Rebounding activity and seasonal context alone provide limited predictive power for scoring output.  \n",
    "While the model captures some signal, additional features (minutes played, shot attempts, assists, etc.) are needed to meaningfully improve detection of high-scoring games.\n",
    "\n",
    "##### Next steps\n",
    "\n",
    "Future improvements may include:\n",
    "- adding richer box-score features\n",
    "- using class balancing techniques\n",
    "- testing non-linear models (Random Forest / Gradient Boosting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58415bf0",
   "metadata": {},
   "source": [
    "## Non- Linear Model: Random Forest\n",
    "\n",
    "Random Forests can capture non-linear relationships and feature interactions.\n",
    "This model provides a strong benchmark without heavy tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65aacdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92     93110\n",
      "           1       0.49      0.01      0.02     15966\n",
      "\n",
      "    accuracy                           0.85    109076\n",
      "   macro avg       0.67      0.50      0.47    109076\n",
      "weighted avg       0.80      0.85      0.79    109076\n",
      "\n",
      "ROC AUC: 0.6942692096766202\n"
     ]
    }
   ],
   "source": [
    "rf= Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\",preprocess),\n",
    "        (\"model\", RandomForestClassifier(\n",
    "            n_estimators=300,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf=rf.predict(X_test)\n",
    "y_prob_rf=rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87be43af",
   "metadata": {},
   "source": [
    "#### Random Forest Benchmark\n",
    "\n",
    "We evaluated a Random Forest classifier to capture potential non-linear relationships and feature interactions.\n",
    "\n",
    "###### Results\n",
    "\n",
    "- Accuracy: 0.85 (inflated by class imbalance)\n",
    "- Recall (20+ pts): 0.01 → most high-scoring games missed\n",
    "- ROC AUC ≈ 0.69 (similar to Logistic Regression)\n",
    "\n",
    "##### Interpretation\n",
    "\n",
    "Performance is nearly identical to Logistic Regression.  \n",
    "This suggests that the current feature set (rebounds + seasonal context) provides limited predictive signal.\n",
    "\n",
    "Model complexity does not improve results, indicating that **feature engineering is likely more important than model choice** at this stage.\n",
    "\n",
    "##### Conclusion\n",
    "\n",
    "Future improvements should prioritize:\n",
    "- richer box-score features (minutes, shots, assists)\n",
    "- rolling averages\n",
    "- contextual game variables\n",
    "\n",
    "rather than additional model tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3693b894",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "We examine the confusion matrix to understand thetypes of errors made by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f74f5365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[92908,   202],\n",
       "       [15773,   193]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm= confusion_matrix(y_test, y_pred_rf)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd283470",
   "metadata": {},
   "source": [
    "#### Confusion Matrix Analysis\n",
    "\n",
    "\n",
    "##### Observations\n",
    "\n",
    "- True Negatives dominate due to class imbalance\n",
    "- Very few False Positives → model is conservative\n",
    "- Large number of False Negatives → most 20+ point games are missed\n",
    "- Only ~1% recall for the positive class\n",
    "\n",
    "##### Interpretation\n",
    "\n",
    "Although overall accuracy is high (≈85%), the model fails to detect most high-scoring performances. This indicates that:\n",
    "\n",
    "- current features provide weak predictive signal\n",
    "- class imbalance biases predictions toward the majority class\n",
    "- accuracy is not an appropriate metric for this task\n",
    "\n",
    "##### Conclusion\n",
    "\n",
    "Improvement should focus on:\n",
    "- richer player features\n",
    "- class balancing techniques\n",
    "- threshold tuning\n",
    "\n",
    "rather than model complexity alone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac790c25",
   "metadata": {},
   "source": [
    "# Modeling Summary\n",
    "\n",
    "## Objective\n",
    "Predict whether a player scores **20+ points in a game** using play-by-play derived features:\n",
    "\n",
    "- Points\n",
    "- Rebounds\n",
    "- Season context\n",
    "\n",
    "Target:\n",
    "`target_20plus = 1 if points ≥ 20`\n",
    "\n",
    "---\n",
    "\n",
    "## Models Tested\n",
    "- Logistic Regression (baseline linear model)\n",
    "- Random Forest (non-linear ensemble)\n",
    "\n",
    "---\n",
    "\n",
    "## Results\n",
    "\n",
    "Both models show similar performance:\n",
    "\n",
    "- Accuracy ≈ 85%\n",
    "- ROC-AUC ≈ 0.69\n",
    "- Very low recall for 20+ games\n",
    "\n",
    "Confusion matrix shows most high-scoring games are **missed**.\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretation\n",
    "\n",
    "- Dataset is **highly imbalanced** (few 20+ games)\n",
    "- Current features provide **limited predictive signal**\n",
    "- Accuracy is misleading — model favors majority class\n",
    "\n",
    "Performance is constrained more by **feature quality than algorithm choice**.\n",
    "\n",
    "---\n",
    "\n",
    "## Future Improvements\n",
    "\n",
    "Main opportunities:\n",
    "\n",
    "- Add rolling stats (last 5–10 games averages)\n",
    "- Include assists, rebounds, minutes, shot attempts\n",
    "- Add team/opponent context\n",
    "- Handle imbalance (class weights / SMOTE)\n",
    "- Try boosting models (XGBoost / LightGBM)\n",
    "- Use time-based validation\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The pipeline successfully demonstrates:\n",
    "\n",
    "- Feature engineering  \n",
    "- Clean modeling workflow  \n",
    "- Reproducible experiments  \n",
    "\n",
    "With richer basketball features, predictive performance is expected to improve substantially.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f6179a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
