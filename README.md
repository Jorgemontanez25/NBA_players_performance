# ğŸ€ NBA Players Performance Analysis & Modeling

ğŸ“Š This project implements an end-to-end data science workflow on historical NBA data â€” from raw SQL ingestion and feature engineering to exploratory analysis, visualization, and predictive modeling.

The objective is to extract meaningful insights from player performance and build models that predict scoring outcomes using real game statistics.

This repository is designed as a professional portfolio project, demonstrating practical skills in:

- Data engineering
- Feature engineering
- Exploratory Data Analysis (EDA)
- Statistical visualization
- Machine learning modeling
- Reproducible workflows

---

## ğŸ“¦ Dataset: NBA Database (Kaggle)

This project uses the **NBA Database** dataset from Kaggle â€” a comprehensive historical dataset containing professional NBA game and player statistics.

Dataset source:  
https://www.kaggle.com/datasets/wyattowalsh/basketball

### Dataset Overview
- ğŸ€ 30 NBA teams
- ğŸ‘¤ 4,800+ players
- ğŸ“† 65,000+ games since 1946
- ğŸ“Š Play-by-play + box scores
- ğŸ“‹ Multiple relational SQL tables

This structure enables event-level analytics and player-level modeling.

---

## â¬‡ï¸ Data Setup

The raw SQLite database is not included due to size (~2GB).

### Steps
1. Download the dataset from Kaggle
2. Place the file at: `data/raw/NBA.sqlite`
3. Run notebooks sequentially inside the `notebooks/` folder

---

## ğŸ¯ Objectives

- Clean and preprocess raw play-by-play data
- Engineer player-level features (points, rebounds, game context)
- Explore trends across players and seasons
- Visualize performance distributions
- Build predictive models for scoring outcomes (20+ points)
- Evaluate models using ROC-AUC and classification metrics

---

## ğŸ“ Project Structure

```
NBA_players_performance/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/           # SQLite database (not tracked)
â”‚   â””â”€â”€ processed/     # Engineered feature tables
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb        # Feature engineering
â”‚   â”œâ”€â”€ 02_analysis.ipynb   # Visualization & insights
â”‚   â””â”€â”€ 03_modeling.ipynb   # ML models & evaluation
â”‚
â”œâ”€â”€ figures/            # Saved plots
â”œâ”€â”€ src/                # Reusable scripts
â””â”€â”€ README.md
```

---

## ğŸ§  Workflow

### 01 â€” EDA & Feature Engineering
- Extract scoring events from play-by-play
- Compute player points per game
- Derive rebound counts
- Merge season and game context
- Produce a clean modeling-ready feature table

### 02 â€” Analysis
- Points distributions
- Player comparisons
- Season trends
- Regular vs playoff performance
- Rebounds exploration as additional signals

### 03 â€” Modeling
- Target: 20+ points classification
- Logistic Regression baseline
- Random Forest benchmark
- Preprocessing pipelines (encoding + scaling)
- ROC-AUC and confusion matrix evaluation

---

## ğŸ“Š Key Results

- Built player-level features directly from raw event data
- Engineered rebounds as additional predictive signals
- Logistic Regression & Random Forest achieved ROC-AUC â‰ˆ **0.69**
- Identified class imbalance as the main modeling challenge
- Demonstrated a complete pipeline from SQL â†’ features â†’ modeling

---

## ğŸ› ï¸ Tools & Technologies

- Python
- Pandas
- NumPy
- Matplotlib / Seaborn
- scikit-learn
- SQLite
- Jupyter Notebook

---

## ğŸš€ Future Work

- Add advanced stats (minutes, shot attempts, efficiency metrics)
- Create rolling averages and recent-form features
- Handle class imbalance (class weights / SMOTE)
- Try Gradient Boosting (XGBoost / LightGBM)
- Perform time-based validation by season
- Deploy model as API or dashboard

---

## ğŸ‘¤ Author

Portfolio project showcasing practical data engineering, analytics, and machine learning skills applied to real-world sports data.



